# car-distance-prediction

# üöó ADAS Prototype: Vehicle Segmentation, Lane Tracking & Distance Estimation

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-Mask%20RCNN-red?style=for-the-badge&logo=pytorch&logoColor=white)
![OpenCV](https://img.shields.io/badge/OpenCV-Computer%20Vision-green?style=for-the-badge&logo=opencv&logoColor=white)
![Status](https://img.shields.io/badge/Status-Active-success?style=for-the-badge)

## üìñ Descripci√≥n

Este proyecto es un prototipo de **Sistema Avanzado de Asistencia al Conductor (ADAS)** desarrollado en Python. Combina t√©cnicas de **Deep Learning** y **Visi√≥n por Computador Cl√°sica** para interpretar el entorno de conducci√≥n en tiempo real.

El objetivo principal del sistema no es solo detectar veh√≠culos, sino **calcular la distancia de seguridad** espec√≠ficamente con los veh√≠culos que se encuentran dentro del carril del conductor, filtrando el tr√°fico irrelevante de carriles adyacentes.

## ‚ú® Caracter√≠sticas Principales

* **üèéÔ∏è Segmentaci√≥n de Instancias (Mask R-CNN):** Detecci√≥n precisa de veh√≠culos utilizando una red ResNet-50 FPN, **fine-tuneada con el dataset Cityscapes** para una mejor precisi√≥n urbana.
* **üõ£Ô∏è Detecci√≥n de Carriles:** Algoritmo de visi√≥n cl√°sica (Sobel/Canny + Sliding Windows) que genera una m√°scara binaria del carril actual.
* **üìè Estimaci√≥n de Distancia:** C√°lculo de la distancia (en metros) utilizando el **modelo de c√°mara estenopeica (Pinhole Camera Model)**, basado en el ancho conocido de cada tipo de veh√≠culo.
* **üéØ Filtrado Inteligente (Data Association):** L√≥gica que cruza las m√°scaras de segmentaci√≥n con la m√°scara del carril para medir la distancia *√∫nicamente* a los veh√≠culos relevantes.
* **üöÄ Optimizaci√≥n ROI (Sky Removal):** Optimizaci√≥n que descarta el procesamiento de la zona superior de la imagen (cielo/horizonte) para reducir la carga de la GPU y aumentar los FPS.

## üß† Pipeline de Procesamiento

El sistema procesa cada frame del video siguiendo este flujo:

1.  **Detecci√≥n de Carriles (Visi√≥n Cl√°sica):**
    * Filtrado de imagen (Sobel + Umbral de color HLS, √≥ Canny ).
    * Transformaci√≥n de perspectiva ("Bird-eye view").
    * Ajuste polin√≥mico de l√≠neas mediante ventanas deslizantes (Sliding Windows) o b√∫squeda priorizada.
2.  **Detecci√≥n de Veh√≠culos (Deep Learning):**
    * **Static ROI:** Recorte de la zona superior de la imagen (cielo) para optimizar inferencia.
    * Inferencia con **Mask R-CNN** sobre la regi√≥n de inter√©s.
    * Re-mapeo de las coordenadas detectadas al frame original.
3.  **Fusi√≥n de Sensores:**
    * Se calcula el centroide inferior de cada veh√≠culo detectado.
    * **Pixel-wise Check:** Se verifica si dicho punto coincide con un p√≠xel activo en la m√°scara del carril generado en el paso 1.
4.  **C√°lculo de Distancia:**
    * Si el veh√≠culo est√° en el carril, se aplica la f√≥rmula $D = (W_{real} \cdot f) / W_{pixel}$.
    * Se asigna un color din√°mico (Rojo $\to$ Verde) seg√∫n la proximidad.
5.  **Visualizaci√≥n:**
    * Los veh√≠culos fuera del carril se marcan en **Cyan**.
    * Los veh√≠culos en trayectoria muestran su distancia y alerta de color.

## üõ†Ô∏è Instalaci√≥n

### Requisitos previos
* Python 3.8+
* GPU NVIDIA (Recomendado para inferencia fluida con CUDA)

### Pasos
1.  Clona el repositorio:
    ```bash
    git clone [https://github.com/tu-usuario/adas-vehicle-segmentation.git](https://github.com/tu-usuario/adas-vehicle-segmentation.git)
    cd adas-vehicle-segmentation
    ```

2.  Crea un entorno virtual e instala las dependencias:
    ```bash
    python -m venv .venv
    .\.venv\Scripts\activate  # En Windows
    # source .venv/bin/activate  # En Linux/macOS
    pip install -r requirements.txt
    ```

    Si no tienes CUDA y no quieres instalarlo para optimizar la inferencia por GPU, instala tambi√©n las siguientes dependencias:

    ```bash
    pip install torch torchvision
    ```

    Si vas a instalar CUDA para tu dispositivo con GPU NVIDIA, o ya lo tienes instalado, debes seguir el siguiente paso opcional.

### (Opcional) Instalaci√≥n de CUDA para GPU NVIDIA

    Para acelerar significativamente la inferencia del modelo, es recomendable instalar **CUDA Toolkit**. Sigue estos pasos:

1. Instala los drivers de NVIDIA.
2. Instala [CUDA Toolkit 11.8+](https://developer.nvidia.com/cuda-downloads).
3. Instala la versi√≥n de [PyTorch](https://pytorch.org/get-started/locally/) compatible con tu CUDA:

#### Verificar que PyTorch detecta CUDA

Escribe en la terminal lo siguiente, para comprobar que CUDA est√° disponible

```python
python -c "import torch; print(torch.cuda.is_available())"
```

Deber√≠a mostrar `True`.

> **Nota:** Si prefieres no instalar CUDA, el modelo funcionar√° con CPU, pero ser√° m√°s lento. La instalaci√≥n de CUDA es completamente opcional.

    

## üöÄ Uso

El archivo principal es distances.py, que viene explicado en distances.ipynb. Los dem√°s archivos son las dependencias que necesita distances.py para funcionar. Cada una viene explicada en su correspondiente Notebook.

Por defecto est√° configurado para funcionar con un v√≠deo de prueba. Puedes ver el resultado ejecutando:
```bash
python distances.py --input display_elements/distance_prediction/videos/video1.mp4 --output results/resultado_final.mp4
```

Debes tambi√©n copiar los archivos de la [carpeta de drive](https://drive.google.com/drive/folders/1GSkANsIEhRQM3dGJAGoPcmQ9cjh6t_2X?usp=drive_link) en tu proyecto.

En caso de querer probar tu propio v√≠deo, se requiere una configuraci√≥n inicial:
1. Se debe calibrar la c√°mara que va a grabar los v√≠deos para obtener su distancia focal. 
2. Se debe tomar una fotograf√≠a de un carril recto y llano, y determinar el trapecio que contiene el carril desde la perspectiva de dicha imagen (v√©ase road_lines.ipynb para entender como hacerlo).

Una vez que se consiguen esos dos par√°metros, se pueden pasar como argumento a distances.py (v√©ase --help).
